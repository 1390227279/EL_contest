# EL_contest: A Courageous Attempt

## AI生成文本检测任务

### 任务分配

#### 1. 检测部分（建议分配1-2人）
- 根据现有代码，使用BERT类模型训练二分类检测器
- 实现对deepseek文本的检测任务

#### 2. 服务器部分（建议分配2-3人）
- 在127.0.0.1:80上构建web服务
- 使用Nginx将用户请求转发到后端检测器监听的端口

### 最终实现效果

1. 用户在浏览器中输入127.0.0.1访问Web页面
2. 用户点击检测按钮，请求发往127.0.0.1:80/api/text子路由
3. Nginx识别到/api后缀，将请求转发给127.0.0.1:10001端口
4. 后端检测器使用Flask路由修饰器，监听/text路由：
    - 识别用户的检测请求和文本
    - 进行检测
5. 检测成功后返回结果，用户在Web页面上看到文本的AI生成概率

### 注意事项

1. **交流协作**
    - 构建交流群沟通进度和问题
    - 优先询问AI（建议gemini 2.5 pro）

2. **开发环境**
    - Windows用户必须启用WSL安装Ubuntu22.04
    - 所有开发必须在Linux环境下进行
    - 推荐工具：VSCode或Cursor

3. **版本管理**
    - 必须使用Git进行代码管理
    - 建议GitHub私有仓库

4. **Python环境**
    - 禁止在默认环境安装包
    - 使用conda/miniconda管理环境
    - 必须在虚拟环境中安装依赖

## 检测任务

### 已有内容
- 提供的训练数据：
    - HC3数据集人类问答数据
    - 使用deepseek API构建的AI回答

### 注意事项
- 负责该部分的同学必须配备NVIDIA独立显卡（如RTX 4060）
- CPU训练速度会非常慢

### 任务目标
1. 数据预处理：
    - 合理清洗数据集
    - 划分训练集/验证集/测试集
2. 环境配置：
    - 安装相关依赖
    - 成功运行训练代码
3. 模型训练：
    - 在CUDA平台上使用BERT类模型
    - 训练二分类检测器
4. 模型验证：
    - 在验证集和测试集上验证准确率

### 进阶内容
- **监督学习方法**：
    - 使用BERT等预训练模型微调
    - 基于带标签数据训练
- **零样本检测方案**：
    - 复现fast-detectGPT等方法
    - 基于Token生成概率寻找特征
    - （需要高性能计算资源，建议RTX 4090）
- **性能优化**：
    - 寻找开源数据集补充训练
    - 确保人机文本平衡
    - 扩展数据领域覆盖面

## 服务器任务

### 任务目标
1. 后端开发：
    - 使用Python Flask构建检测服务
2. 前端开发：
    - 实现Web页面和用户交互
    - 建议使用Vue框架
    - 可借助AI工具生成代码
3. 服务部署：
    - 配置Nginx服务（Linux环境）

### 进阶内容
1. 扩展功能：
    - 构建数据库和用户系统
2. 部署优化：
    - 使用Docker容器化部署
    - 部署到阿里云服务器（A10显卡按量付费≈10元/h）
    - 从本地迁移到公网环境
3. 知识扩展：
    - 学习计算机网络相关知识


> 注：这些内容是计算机专业的基础技能，建议全员掌握